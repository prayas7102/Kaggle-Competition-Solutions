{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import (\n",
    "    PowerTransformer,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "excel_file_path = \"./train.csv\"\n",
    "df = pd.read_csv(excel_file_path, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Listening_Time_minutes'] != 0)]\n",
    "df['Listening_Time_minutes'] = np.log1p(df['Listening_Time_minutes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_eda():\n",
    "    profile = ProfileReport(\n",
    "        pd.concat([df], axis=1),\n",
    "        title=\"Pandas Profiling Report\",\n",
    "        explorative=True,\n",
    "    )\n",
    "    profile.to_file(\"pandas_profiling_report.html\")\n",
    "\n",
    "\n",
    "# gen_eda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Podcast_Name</th>\n",
       "      <th>Episode_Title</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Publication_Day</th>\n",
       "      <th>Publication_Time</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Episode_Sentiment</th>\n",
       "      <th>Listening_Time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>381030</th>\n",
       "      <td>381030</td>\n",
       "      <td>Fashion Forward</td>\n",
       "      <td>Episode 8</td>\n",
       "      <td>106.42</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>62.85</td>\n",
       "      <td>Monday</td>\n",
       "      <td>Night</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>3.996938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656144</th>\n",
       "      <td>656144</td>\n",
       "      <td>Money Matters</td>\n",
       "      <td>Episode 62</td>\n",
       "      <td>81.79</td>\n",
       "      <td>Business</td>\n",
       "      <td>80.43</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>49.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>4.257373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704976</th>\n",
       "      <td>704976</td>\n",
       "      <td>Game Day</td>\n",
       "      <td>Episode 78</td>\n",
       "      <td>68.27</td>\n",
       "      <td>Sports</td>\n",
       "      <td>55.81</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>61.37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>3.561739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519036</th>\n",
       "      <td>519036</td>\n",
       "      <td>Melody Mix</td>\n",
       "      <td>Episode 81</td>\n",
       "      <td>116.21</td>\n",
       "      <td>Music</td>\n",
       "      <td>66.03</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>13.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>4.710678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144367</th>\n",
       "      <td>144367</td>\n",
       "      <td>Digital Digest</td>\n",
       "      <td>Episode 43</td>\n",
       "      <td>117.29</td>\n",
       "      <td>Technology</td>\n",
       "      <td>60.32</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Evening</td>\n",
       "      <td>13.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>4.747438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     Podcast_Name Episode_Title  Episode_Length_minutes  \\\n",
       "381030  381030  Fashion Forward     Episode 8                  106.42   \n",
       "656144  656144    Money Matters    Episode 62                   81.79   \n",
       "704976  704976         Game Day    Episode 78                   68.27   \n",
       "519036  519036       Melody Mix    Episode 81                  116.21   \n",
       "144367  144367   Digital Digest    Episode 43                  117.29   \n",
       "\n",
       "             Genre  Host_Popularity_percentage Publication_Day  \\\n",
       "381030   Lifestyle                       62.85          Monday   \n",
       "656144    Business                       80.43       Wednesday   \n",
       "704976      Sports                       55.81         Tuesday   \n",
       "519036       Music                       66.03        Saturday   \n",
       "144367  Technology                       60.32         Tuesday   \n",
       "\n",
       "       Publication_Time  Guest_Popularity_percentage  Number_of_Ads  \\\n",
       "381030            Night                         0.65            0.0   \n",
       "656144          Evening                        49.53            0.0   \n",
       "704976        Afternoon                        61.37            1.0   \n",
       "519036          Evening                        13.15            1.0   \n",
       "144367          Evening                        13.71            1.0   \n",
       "\n",
       "       Episode_Sentiment  Listening_Time_minutes  \n",
       "381030          Negative                3.996938  \n",
       "656144          Negative                4.257373  \n",
       "704976          Positive                3.561739  \n",
       "519036          Positive                4.710678  \n",
       "144367          Negative                4.747438  "
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Episode_Length_minutes</th>\n",
       "      <th>Host_Popularity_percentage</th>\n",
       "      <th>Guest_Popularity_percentage</th>\n",
       "      <th>Number_of_Ads</th>\n",
       "      <th>Listening_Time_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>741449.000000</td>\n",
       "      <td>655066.000000</td>\n",
       "      <td>741449.000000</td>\n",
       "      <td>598546.000000</td>\n",
       "      <td>741448.000000</td>\n",
       "      <td>741449.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>374957.717282</td>\n",
       "      <td>65.185957</td>\n",
       "      <td>59.836673</td>\n",
       "      <td>52.328988</td>\n",
       "      <td>1.348355</td>\n",
       "      <td>3.619211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>216507.054088</td>\n",
       "      <td>32.568739</td>\n",
       "      <td>22.874244</td>\n",
       "      <td>28.493094</td>\n",
       "      <td>1.152670</td>\n",
       "      <td>0.777568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>187430.000000</td>\n",
       "      <td>36.730000</td>\n",
       "      <td>39.380000</td>\n",
       "      <td>28.340000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.213869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>374926.000000</td>\n",
       "      <td>64.420000</td>\n",
       "      <td>60.020000</td>\n",
       "      <td>53.780000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.802549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>562461.000000</td>\n",
       "      <td>94.330000</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>76.760000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.190771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>749999.000000</td>\n",
       "      <td>325.240000</td>\n",
       "      <td>119.460000</td>\n",
       "      <td>119.910000</td>\n",
       "      <td>103.910000</td>\n",
       "      <td>4.795543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id  Episode_Length_minutes  Host_Popularity_percentage  \\\n",
       "count  741449.000000           655066.000000               741449.000000   \n",
       "mean   374957.717282               65.185957                   59.836673   \n",
       "std    216507.054088               32.568739                   22.874244   \n",
       "min         0.000000                0.000000                    1.300000   \n",
       "25%    187430.000000               36.730000                   39.380000   \n",
       "50%    374926.000000               64.420000                   60.020000   \n",
       "75%    562461.000000               94.330000                   79.500000   \n",
       "max    749999.000000              325.240000                  119.460000   \n",
       "\n",
       "       Guest_Popularity_percentage  Number_of_Ads  Listening_Time_minutes  \n",
       "count                598546.000000  741448.000000           741449.000000  \n",
       "mean                     52.328988       1.348355                3.619211  \n",
       "std                      28.493094       1.152670                0.777568  \n",
       "min                       0.000000       0.000000                0.000560  \n",
       "25%                      28.340000       0.000000                3.213869  \n",
       "50%                      53.780000       1.000000                3.802549  \n",
       "75%                      76.760000       2.000000                4.190771  \n",
       "max                     119.910000     103.910000                4.795543  "
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 120984\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=[\n",
    "    \"Episode_Length_minutes\",\n",
    "    # \"Guest_Popularity_percentage\"\n",
    "])\n",
    "print(df[\"Episode_Length_minutes\"].isnull().sum(), df[\"Guest_Popularity_percentage\"].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, outlier_dict):\n",
    "    for distribution, category in outlier_dict.items():\n",
    "        if distribution == \"normal\":\n",
    "            for cat in category:\n",
    "                upper_limit = df[cat].mean() + 3 * df[cat].std()\n",
    "                lower_limit = df[cat].mean() - 3 * df[cat].std()\n",
    "                print(cat, upper_limit, lower_limit)\n",
    "                # capping\n",
    "                # df[cat] = np.where(df[cat] > upper_limit,upper_limit,np.where(df[cat] < lower_limit, lower_limit, df[cat]))\n",
    "                # Trimming\n",
    "                df = df[(df[cat] < upper_limit) & (df[cat] > lower_limit)]\n",
    "        elif distribution == \"skew\":\n",
    "            for cat in category:\n",
    "                percentile25 = df[cat].quantile(0.4)\n",
    "                percentile75 = df[cat].quantile(0.75)\n",
    "                iqr = percentile75 - percentile25\n",
    "                upper_limit = percentile75 + 1.5 * iqr\n",
    "                lower_limit = percentile25 - 1.5 * iqr\n",
    "                print(cat, upper_limit, lower_limit)\n",
    "                # capping\n",
    "                # df[cat] = np.where(\n",
    "                #     df[cat] > upper_limit,\n",
    "                #     upper_limit,\n",
    "                #     np.where(df[cat] < lower_limit, lower_limit, df[cat]),\n",
    "                # )\n",
    "                # Trimming\n",
    "                df = df[(df[cat] < upper_limit) & (df[cat] > lower_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dict = {\n",
    "    \"normal\": [],\n",
    "    \"skew\": [],\n",
    "}\n",
    "\n",
    "\n",
    "def pre_process(df):\n",
    "    df[\"Publication_Day\"] = (\n",
    "        df[\"Publication_Day\"]\n",
    "        .map(\n",
    "            {\n",
    "                \"Monday\": 1, \"Tuesday\": 2, \"Wednesday\": 3, \"Thursday\": 4, \"Friday\": 5, \"Saturday\": 6, \"Sunday\": 7,\n",
    "            }\n",
    "        )\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    df[\"Publication_Time\"] = (\n",
    "        df[\"Publication_Time\"]\n",
    "        .map({\"Morning\": 1, \"Afternoon\": 2, \"Evening\": 3, \"Night\": 4})\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    df[\"Episode_Sentiment\"] = (\n",
    "        df[\"Episode_Sentiment\"]\n",
    "        .map({\"Negative\": 0, \"Neutral\": 1, \"Positive\": 2})\n",
    "        .fillna(0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pre_process(df)\n",
    "df = remove_outliers(df, outlier_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(524052, 9)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "def get_X_Y(df):\n",
    "    X = df.drop(columns=[\"id\", \"Listening_Time_minutes\", \"Episode_Title\"])\n",
    "    Y = df[\"Listening_Time_minutes\"]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, Y = get_X_Y(df)\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=5\n",
    ")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of categorical column names\n",
    "categories_order = {\n",
    "    \"Publication_Day\": sorted(list(df[\"Publication_Day\"].unique())),\n",
    "    \"Publication_Time\": sorted(list(df[\"Publication_Time\"].unique())),\n",
    "    \"Episode_Sentiment\": sorted(list(df[\"Episode_Sentiment\"].unique())),\n",
    "}\n",
    "categorical_feat_ord = list(categories_order.keys())\n",
    "categorical_feat_nom = [ \"Podcast_Name\", \"Genre\"]\n",
    "categorical = categorical_feat_nom + categorical_feat_ord\n",
    "numerical_features = [col for col in X_train.columns if col not in categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate transformers for categorical and numerical features\n",
    "\n",
    "# trf = FunctionTransformer(np.log1p, validate=True)\n",
    "# trf = PowerTransformer()\n",
    "# trf = FunctionTransformer(np.sqrt, validate=True)\n",
    "# trf = FunctionTransformer(np.sin)\n",
    "trf = StandardScaler()\n",
    "# trf = MinMaxScaler()\n",
    "trf = FunctionTransformer(np.log1p, validate=True)\n",
    "# Add Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"mean\")), \n",
    "           (\"poly\", poly),\n",
    "           (\"log\", trf)]\n",
    ")\n",
    "categorical_transformer_onehot = Pipeline(\n",
    "    steps=[\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "categorical_transformer_ordinal = Pipeline(\n",
    "    steps=[\n",
    "        (\"ord\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Podcast_Name  Episode_Length_minutes       Genre  \\\n",
      "472403      Market Masters                   42.25    Business   \n",
      "125853         Funny Folks                  102.39      Comedy   \n",
      "96601     Lifestyle Lounge                   65.30   Lifestyle   \n",
      "577975           Humor Hub                    6.70      Comedy   \n",
      "668138     Business Briefs                   47.30    Business   \n",
      "...                    ...                     ...         ...   \n",
      "639062         Sound Waves                   55.68       Music   \n",
      "142615         Tech Trends                  116.82  Technology   \n",
      "623682       Fitness First                   98.28      Health   \n",
      "21346     Lifestyle Lounge                   90.38   Lifestyle   \n",
      "341072  True Crime Stories                   81.89  True Crime   \n",
      "\n",
      "        Host_Popularity_percentage  Publication_Day  Publication_Time  \\\n",
      "472403                       41.22                1                 1   \n",
      "125853                       60.21                6                 2   \n",
      "96601                        51.85                5                 3   \n",
      "577975                       36.73                7                 3   \n",
      "668138                       70.92                7                 1   \n",
      "...                            ...              ...               ...   \n",
      "639062                       78.56                4                 4   \n",
      "142615                       31.39                4                 2   \n",
      "623682                       22.73                1                 3   \n",
      "21346                        41.39                2                 4   \n",
      "341072                       27.25                3                 1   \n",
      "\n",
      "        Guest_Popularity_percentage  Number_of_Ads  Episode_Sentiment  \n",
      "472403                          NaN            0.0                  2  \n",
      "125853                        37.48            2.0                  1  \n",
      "96601                          5.48            0.0                  2  \n",
      "577975                         5.62            3.0                  1  \n",
      "668138                        28.40            3.0                  2  \n",
      "...                             ...            ...                ...  \n",
      "639062                        56.72            1.0                  2  \n",
      "142615                        83.75            2.0                  0  \n",
      "623682                        43.07            1.0                  2  \n",
      "21346                           NaN            0.0                  2  \n",
      "341072                        52.35            1.0                  2  \n",
      "\n",
      "[524052 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", categorical_transformer_onehot, categorical_feat_nom),\n",
    "        (\"cat_1\", categorical_transformer_ordinal, categorical_feat_ord),\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model = Ridge(alpha=0.1)\n",
    "# model = XGBRegressor(objective='reg:squarederror', scale_pos_weight=1)\n",
    "\n",
    "pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the correlation matrix\n",
    "# correlation_matrix = df.corr()\n",
    "\n",
    "# # Save the correlation matrix to a CSV file\n",
    "# correlation_matrix.to_csv('correlation_matrix.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.pkl\n",
      "Mean Squared Error: 0.08005768085204351\n",
      "Root Mean Squared Error: 0.2829446604056057\n",
      "R² Score: 0.8688\n",
      "Adjusted R² Score: 0.8688\n",
      "Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted pipeline as a .pkl file\n",
    "filename_pkl = \"model.pkl\"\n",
    "pickle.dump(pipeline, open(filename_pkl, \"wb\"))\n",
    "print(f\"Model saved as {filename_pkl}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "\n",
    "\n",
    "def adjusted_r2_score(y_true, y_pred, X):\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    n = len(y_true)  # number of samples\n",
    "    k = X.shape[1]  # number of features\n",
    "    adj_r2 = 1 - (1 - r2) * ((n - 1) / (n - k - 1))\n",
    "    return r2, adj_r2\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "r2, adj_r2 = adjusted_r2_score(Y_test, y_pred, X_test)\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"Adjusted R² Score: {adj_r2:.4f}\")\n",
    "\n",
    "# scores = cross_val_score(model, X_train, Y_train, cv=5)\n",
    "# print(\"Cross-validation scores:\", scores)\n",
    "# print(\"Mean score:\", scores.mean())\n",
    "\n",
    "# Define the columns expected by the model\n",
    "column_names = X_train.columns\n",
    "\n",
    "\n",
    "def generate_submission(test_file):\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(test_file)\n",
    "    df = pd.DataFrame(df)\n",
    "    # Replace empty strings with NaN\n",
    "    df.replace(\"\", np.nan, inplace=True)\n",
    "    df = pre_process(df)\n",
    "    # Select the relevant columns\n",
    "    filtered_df = df[column_names]\n",
    "    predictions = pipeline.predict(filtered_df)\n",
    "    # Load the original test file to keep the PassengerId column\n",
    "    original_df = pd.read_csv(test_file)\n",
    "    original_df[\"Listening_Time_minutes\"] = predictions\n",
    "    original_df[\"Listening_Time_minutes\"] = np.expm1(\n",
    "        original_df[\"Listening_Time_minutes\"]\n",
    "    )\n",
    "    # Save the results to a new CSV file\n",
    "    submission_df = original_df[[\"id\", \"Listening_Time_minutes\"]]\n",
    "    submission_df.to_csv(\"submission.csv\", index=False)\n",
    "    print(\"Submission file saved as 'submission.csv'\")\n",
    "\n",
    "\n",
    "# Generate the submission\n",
    "test_file = \"test.csv\"\n",
    "generate_submission(test_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
