{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import (\n",
    "    PowerTransformer,\n",
    "    StandardScaler,\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    ")\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.pipeline import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "excel_file_path = \"./creditcard1.csv\"\n",
    "df = pd.read_csv(excel_file_path, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67108</th>\n",
       "      <td>52501.0</td>\n",
       "      <td>1.229890</td>\n",
       "      <td>0.148845</td>\n",
       "      <td>0.146808</td>\n",
       "      <td>0.521021</td>\n",
       "      <td>-0.325817</td>\n",
       "      <td>-0.604660</td>\n",
       "      <td>-0.148411</td>\n",
       "      <td>0.071443</td>\n",
       "      <td>0.082409</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>-0.934802</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>-0.088763</td>\n",
       "      <td>0.164583</td>\n",
       "      <td>0.103386</td>\n",
       "      <td>-0.040241</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282992</th>\n",
       "      <td>172122.0</td>\n",
       "      <td>0.822027</td>\n",
       "      <td>-2.365180</td>\n",
       "      <td>-2.013855</td>\n",
       "      <td>0.615910</td>\n",
       "      <td>-0.607972</td>\n",
       "      <td>-0.262464</td>\n",
       "      <td>0.773010</td>\n",
       "      <td>-0.283916</td>\n",
       "      <td>1.148864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191159</td>\n",
       "      <td>-0.736414</td>\n",
       "      <td>-0.347905</td>\n",
       "      <td>0.497661</td>\n",
       "      <td>-0.269836</td>\n",
       "      <td>-0.172189</td>\n",
       "      <td>-0.157457</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>652.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182758</th>\n",
       "      <td>125794.0</td>\n",
       "      <td>-2.718769</td>\n",
       "      <td>0.665312</td>\n",
       "      <td>-1.750642</td>\n",
       "      <td>0.345594</td>\n",
       "      <td>2.143153</td>\n",
       "      <td>-0.400648</td>\n",
       "      <td>1.742902</td>\n",
       "      <td>-0.954034</td>\n",
       "      <td>0.493019</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203492</td>\n",
       "      <td>0.633018</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>-0.343731</td>\n",
       "      <td>-0.858093</td>\n",
       "      <td>-1.640620</td>\n",
       "      <td>-0.417682</td>\n",
       "      <td>52.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151719</th>\n",
       "      <td>97248.0</td>\n",
       "      <td>1.994146</td>\n",
       "      <td>-0.218142</td>\n",
       "      <td>-1.062654</td>\n",
       "      <td>0.293147</td>\n",
       "      <td>0.100398</td>\n",
       "      <td>-0.267599</td>\n",
       "      <td>-0.193873</td>\n",
       "      <td>-0.153338</td>\n",
       "      <td>2.108615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012331</td>\n",
       "      <td>0.459700</td>\n",
       "      <td>0.060589</td>\n",
       "      <td>0.773688</td>\n",
       "      <td>0.167847</td>\n",
       "      <td>0.097727</td>\n",
       "      <td>-0.061668</td>\n",
       "      <td>-0.068930</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68790</th>\n",
       "      <td>53247.0</td>\n",
       "      <td>-0.749912</td>\n",
       "      <td>0.448790</td>\n",
       "      <td>1.533313</td>\n",
       "      <td>-1.403425</td>\n",
       "      <td>-0.041087</td>\n",
       "      <td>-0.644681</td>\n",
       "      <td>0.397774</td>\n",
       "      <td>0.203916</td>\n",
       "      <td>-0.036830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046391</td>\n",
       "      <td>-0.260775</td>\n",
       "      <td>-0.038609</td>\n",
       "      <td>-0.010083</td>\n",
       "      <td>-0.362843</td>\n",
       "      <td>0.726389</td>\n",
       "      <td>0.233238</td>\n",
       "      <td>0.161877</td>\n",
       "      <td>22.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "67108    52501.0  1.229890  0.148845  0.146808  0.521021 -0.325817 -0.604660   \n",
       "282992  172122.0  0.822027 -2.365180 -2.013855  0.615910 -0.607972 -0.262464   \n",
       "182758  125794.0 -2.718769  0.665312 -1.750642  0.345594  2.143153 -0.400648   \n",
       "151719   97248.0  1.994146 -0.218142 -1.062654  0.293147  0.100398 -0.267599   \n",
       "68790    53247.0 -0.749912  0.448790  1.533313 -1.403425 -0.041087 -0.644681   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "67108  -0.148411  0.071443  0.082409  ... -0.277678 -0.934802  0.096725   \n",
       "282992  0.773010 -0.283916  1.148864  ...  0.191159 -0.736414 -0.347905   \n",
       "182758  1.742902 -0.954034  0.493019  ... -0.203492  0.633018  0.002111   \n",
       "151719 -0.193873 -0.153338  2.108615  ... -0.012331  0.459700  0.060589   \n",
       "68790   0.397774  0.203916 -0.036830  ... -0.046391 -0.260775 -0.038609   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "67108  -0.088763  0.164583  0.103386 -0.040241  0.013710    4.49      0  \n",
       "282992  0.497661 -0.269836 -0.172189 -0.157457  0.059176  652.72      0  \n",
       "182758  0.139716 -0.343731 -0.858093 -1.640620 -0.417682   52.98      0  \n",
       "151719  0.773688  0.167847  0.097727 -0.061668 -0.068930   15.99      0  \n",
       "68790  -0.010083 -0.362843  0.726389  0.233238  0.161877   22.84      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "      <td>283726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94811.077600</td>\n",
       "      <td>0.005917</td>\n",
       "      <td>-0.004135</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>-0.002966</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>-0.001596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.001763</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>88.472687</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47481.047891</td>\n",
       "      <td>1.948026</td>\n",
       "      <td>1.646703</td>\n",
       "      <td>1.508682</td>\n",
       "      <td>1.414184</td>\n",
       "      <td>1.377008</td>\n",
       "      <td>1.331931</td>\n",
       "      <td>1.227664</td>\n",
       "      <td>1.179054</td>\n",
       "      <td>1.095492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723909</td>\n",
       "      <td>0.724550</td>\n",
       "      <td>0.623702</td>\n",
       "      <td>0.605627</td>\n",
       "      <td>0.521220</td>\n",
       "      <td>0.482053</td>\n",
       "      <td>0.395744</td>\n",
       "      <td>0.328027</td>\n",
       "      <td>250.399437</td>\n",
       "      <td>0.040796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54204.750000</td>\n",
       "      <td>-0.915951</td>\n",
       "      <td>-0.600321</td>\n",
       "      <td>-0.889682</td>\n",
       "      <td>-0.850134</td>\n",
       "      <td>-0.689830</td>\n",
       "      <td>-0.769031</td>\n",
       "      <td>-0.552509</td>\n",
       "      <td>-0.208828</td>\n",
       "      <td>-0.644221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228305</td>\n",
       "      <td>-0.542700</td>\n",
       "      <td>-0.161703</td>\n",
       "      <td>-0.354453</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>-0.326763</td>\n",
       "      <td>-0.070641</td>\n",
       "      <td>-0.052818</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.500000</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.063949</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>-0.053468</td>\n",
       "      <td>-0.275168</td>\n",
       "      <td>0.040859</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>-0.052596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029441</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.041016</td>\n",
       "      <td>0.016278</td>\n",
       "      <td>-0.052172</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.011288</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139298.000000</td>\n",
       "      <td>1.316068</td>\n",
       "      <td>0.800283</td>\n",
       "      <td>1.026960</td>\n",
       "      <td>0.739647</td>\n",
       "      <td>0.612218</td>\n",
       "      <td>0.396792</td>\n",
       "      <td>0.570474</td>\n",
       "      <td>0.325704</td>\n",
       "      <td>0.595977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186194</td>\n",
       "      <td>0.528245</td>\n",
       "      <td>0.147748</td>\n",
       "      <td>0.439738</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>0.240261</td>\n",
       "      <td>0.091208</td>\n",
       "      <td>0.078276</td>\n",
       "      <td>77.510000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean    94811.077600       0.005917      -0.004135       0.001613   \n",
       "std     47481.047891       1.948026       1.646703       1.508682   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54204.750000      -0.915951      -0.600321      -0.889682   \n",
       "50%     84692.500000       0.020384       0.063949       0.179963   \n",
       "75%    139298.000000       1.316068       0.800283       1.026960   \n",
       "max    172792.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean       -0.002966       0.001828      -0.001139       0.001801   \n",
       "std         1.414184       1.377008       1.331931       1.227664   \n",
       "min        -5.683171    -113.743307     -26.160506     -43.557242   \n",
       "25%        -0.850134      -0.689830      -0.769031      -0.552509   \n",
       "50%        -0.022248      -0.053468      -0.275168       0.040859   \n",
       "75%         0.739647       0.612218       0.396792       0.570474   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  283726.000000  283726.000000  ...  283726.000000  283726.000000   \n",
       "mean       -0.000854      -0.001596  ...      -0.000371      -0.000015   \n",
       "std         1.179054       1.095492  ...       0.723909       0.724550   \n",
       "min       -73.216718     -13.434066  ...     -34.830382     -10.933144   \n",
       "25%        -0.208828      -0.644221  ...      -0.228305      -0.542700   \n",
       "50%         0.021898      -0.052596  ...      -0.029441       0.006675   \n",
       "75%         0.325704       0.595977  ...       0.186194       0.528245   \n",
       "max        20.007208      15.594995  ...      27.202839      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000   \n",
       "mean        0.000198       0.000214      -0.000232       0.000149   \n",
       "std         0.623702       0.605627       0.521220       0.482053   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161703      -0.354453      -0.317485      -0.326763   \n",
       "50%        -0.011159       0.041016       0.016278      -0.052172   \n",
       "75%         0.147748       0.439738       0.350667       0.240261   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount          Class  \n",
       "count  283726.000000  283726.000000  283726.000000  283726.000000  \n",
       "mean        0.001763       0.000547      88.472687       0.001667  \n",
       "std         0.395744       0.328027     250.399437       0.040796  \n",
       "min       -22.565679     -15.430084       0.000000       0.000000  \n",
       "25%        -0.070641      -0.052818       5.600000       0.000000  \n",
       "50%         0.001479       0.011288      22.000000       0.000000  \n",
       "75%         0.091208       0.078276      77.510000       0.000000  \n",
       "max        31.612198      33.847808   25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, outlier_dict):\n",
    "    for distribution, category in outlier_dict.items():\n",
    "        if distribution == \"normal\":\n",
    "            for cat in category:\n",
    "                upper_limit = df[cat].mean() + 3 * df[cat].std()\n",
    "                lower_limit = df[cat].mean() - 3 * df[cat].std()\n",
    "                print(cat, upper_limit, lower_limit)\n",
    "                # capping\n",
    "                # df[cat] = np.where(df[cat] > upper_limit,upper_limit,np.where(df[cat] < lower_limit, lower_limit, df[cat]))\n",
    "                # Trimming\n",
    "                df = df[(df[cat] < upper_limit) & (df[cat] > lower_limit)]\n",
    "        elif distribution == \"skew\":\n",
    "            for cat in category:\n",
    "                percentile25 = df[cat].quantile(0.25)\n",
    "                percentile75 = df[cat].quantile(0.75)\n",
    "                iqr = percentile75 - percentile25\n",
    "                upper_limit = percentile75 + 1.5 * iqr\n",
    "                lower_limit = percentile25 - 1.5 * iqr\n",
    "                print(cat, upper_limit, lower_limit)\n",
    "                # capping\n",
    "                # df[cat] = np.where(\n",
    "                #     df[cat] > upper_limit,\n",
    "                #     upper_limit,\n",
    "                #     np.where(df[cat] < lower_limit, lower_limit, df[cat]),\n",
    "                # )\n",
    "                # Trimming\n",
    "                df = df[(df[cat] < upper_limit) & (df[cat] > lower_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dict = {\n",
    "    \"normal\": [],\n",
    "    \"skew\": [],\n",
    "}\n",
    "\n",
    "def pre_process(df):\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pre_process(df)\n",
    "df = remove_outliers(df, outlier_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226980, 29)\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "def get_X_Y(df):\n",
    "    X = df.drop(columns=[\"Class\", \"Time\"])\n",
    "    Y = df[\"Class\"]\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "X, Y = get_X_Y(df)\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.20, random_state=5\n",
    ")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of categorical column names\n",
    "numerical_features = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate transformers for categorical and numerical features\n",
    "\n",
    "# trf = FunctionTransformer(np.log1p, validate=True)\n",
    "# trf = PowerTransformer()\n",
    "# trf = FunctionTransformer(np.sqrt, validate=True)\n",
    "# trf = FunctionTransformer(np.sin)\n",
    "trf = StandardScaler()\n",
    "poly = PolynomialFeatures(degree=3,include_bias=False)\n",
    "# trf = MinMaxScaler()\n",
    "\n",
    "numerical_transformer_1 = Pipeline(\n",
    "    steps=[\n",
    "        (\"log\", trf),\n",
    "        (\"poly\", poly),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer_1, numerical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = LogisticRegression(\n",
    "    verbose=0,\n",
    "    max_iter=1000,\n",
    "    class_weight={0:0.5,1:8},\n",
    "    penalty='elasticnet',\n",
    "    solver='saga',\n",
    "    l1_ratio=0.15,\n",
    ")\n",
    "\n",
    "# Define the pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    (\"preprocessor\", preprocessor), \n",
    "    # ('smote', SMOTE(random_state=42, k_neighbors=5, sampling_strategy=0.20)),\n",
    "    (\"model\", model)])\n",
    "\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9992598597257957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.9994360801842822\n",
      "[[56625    29]\n",
      " [   13    79]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56654\n",
      "           1       0.73      0.86      0.79        92\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.87      0.93      0.89     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the tuned model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\n",
    "    \"Cross-validation accuracy:\",\n",
    "    cross_val_score(pipeline, X_test, Y_test, cv=3, scoring=\"accuracy\").mean(),\n",
    ")\n",
    "\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "report = classification_report(Y_test, y_pred, target_names=['0', '1'])\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
